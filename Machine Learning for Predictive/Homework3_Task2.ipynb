{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsoOZXs3KsHh"
      },
      "outputs": [],
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1_7QW_sb89PhodAUL6W0XRzZvFuXGITsq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C_KZXguRCsi",
        "outputId": "ab8e5201-b920-4af6-8be2-e0e258cb7c93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_7QW_sb89PhodAUL6W0XRzZvFuXGITsq\n",
            "To: /content/MobileNetV2.mxnet-master.zip\n",
            "100% 13.2M/13.2M [00:00<00:00, 34.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 18_e1gBcQxf_S-FnhxIc3b-D8mVNFZ9WV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYV6vjatUDeC",
        "outputId": "7a34827d-1b5b-4f59-a575-6568691d2a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18_e1gBcQxf_S-FnhxIc3b-D8mVNFZ9WV\n",
            "To: /content/kaggle.json\n",
            "100% 65.0/65.0 [00:00<00:00, 276kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_WGwVP8rWD",
        "outputId": "470a4f6e-a4c0-4741-8bc4-c0e8c2d6306d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIqrqS7v9EeQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Set your Kaggle API credentials\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"maryamsaa\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"b73d47e88e6150c7dbb3ae61c96b1024\"\n",
        "\n",
        "# Specify the competition name\n",
        "competition_name = \"dogs-vs-cats-redux-kernels-edition\"\n",
        "\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the train.zip file\n",
        "api.competition_download_file(competition=competition_name, file_name=\"train.zip\")\n",
        "\n",
        "# Download the test.zip file\n",
        "api.competition_download_file(competition=competition_name, file_name=\"test.zip\")\n"
      ],
      "metadata": {
        "id": "OO-gX5loxwau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc76e77-ac60-4386-8a7b-af592277c205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 544M/544M [00:12<00:00, 46.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading test.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 271M/271M [00:06<00:00, 43.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbnvdcpW9bd4"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the paths to the zip files\n",
        "train_zip_path = \"train.zip\"\n",
        "test_zip_path = \"test.zip\"\n",
        "MobileNet_zip_path = \"MobileNetV2.mxnet-master.zip\"\n",
        "\n",
        "# Extract the contents of train.zip in the same directory\n",
        "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(train_zip_path))\n",
        "\n",
        "# Extract the contents of test.zip in the same directory\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(test_zip_path))\n",
        "\n",
        "# Extract the contents of MobileNetV2.mxnet-master.zip in the same directory\n",
        "with zipfile.ZipFile(MobileNet_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(MobileNet_zip_path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eImuZIIEqgYV",
        "outputId": "526acc7b-e836-4ca4-d096-558179f35385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet==1.5.1\n",
            "  Downloading mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet==1.5.1)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2023.7.22)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install mxnet==1.5.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A92XHwf6Lo9m"
      },
      "outputs": [],
      "source": [
        "import mxnet as mx\n",
        "import numpy as np\n",
        "np.bool = np.bool_\n",
        "\n",
        "symbol_file = 'MobileNetV2.mxnet-master/mbnv2'\n",
        "params_file = 'MobileNetV2.mxnet-master/mbnv2-0000.params'\n",
        "\n",
        "# Load the model\n",
        "sym, arg_params, aux_params = mx.model.load_checkpoint(symbol_file, 0)\n",
        "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
        "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))],\n",
        "         label_shapes=mod._label_shapes)\n",
        "mod.set_params(arg_params, aux_params, allow_missing=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJxXfKtbCqdy"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "# define a simple data batch\n",
        "from collections import namedtuple\n",
        "Batch = namedtuple('Batch', ['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD5aDnyRMG3r"
      },
      "outputs": [],
      "source": [
        "def get_image(url, show=False):\n",
        "    if url.startswith('http'):\n",
        "        # download and show the image\n",
        "        fname = mx.test_utils.download(url)\n",
        "    else:\n",
        "        fname = url\n",
        "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
        "    if img is None:\n",
        "         return None\n",
        "    if show:\n",
        "         plt.imshow(img)\n",
        "         plt.axis('off')\n",
        "    # convert into format (batch, RGB, width, height)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.swapaxes(img, 0, 2)\n",
        "    img = np.swapaxes(img, 1, 2)\n",
        "    img = img[np.newaxis, :]\n",
        "    return img\n",
        "\n",
        "def predict(url):\n",
        "    img = get_image(url, show=True)\n",
        "    # compute the predict probabilities\n",
        "    mod.forward(Batch([mx.nd.array(img)]))\n",
        "    prob = mod.get_outputs()[0].asnumpy()\n",
        "    # print the top-5\n",
        "    prob = np.squeeze(prob)\n",
        "    a = np.argsort(prob)[::-1]\n",
        "    for i in a[0:5]:\n",
        "        print('probability=%f, class=%s' %(prob[i], labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5YUQ5BfMUMK",
        "outputId": "74ebe04c-5794-4282-836a-8fb2c5928daa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stage4_2_batchnorm0_beta',\n",
              " 'stage4_2_batchnorm0_running_mean',\n",
              " 'stage4_2_batchnorm0_running_var',\n",
              " 'stage4_2_batchnorm0_fwd_output',\n",
              " 'stage4_2_relu6_fwd_output',\n",
              " 'pool1_fwd_output',\n",
              " 'flatten1_reshape0_output',\n",
              " 'dense1_weight',\n",
              " 'dense1_bias',\n",
              " 'dense1_fwd_output']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# list the last 10 layers\n",
        "all_layers = sym.get_internals()\n",
        "all_layers.list_outputs()[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdkrX6vYMXmy"
      },
      "outputs": [],
      "source": [
        "fe_sym = all_layers['flatten1_reshape0_output']\n",
        "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
        "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
        "fe_mod.set_params(arg_params, aux_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUEVSw9qM_x0"
      },
      "outputs": [],
      "source": [
        "def get_features(img):\n",
        "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
        "    features = fe_mod.get_outputs()[0].asnumpy()\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EClrxrFjNEM0",
        "outputId": "173c0566-66a0-4675-d8f5-b580b55d76c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.4688736  0.9470865  0.29574123 ... 0.8793548  0.4675708  0.03323477]]\n",
            " shape: (1, 1280)\n"
          ]
        }
      ],
      "source": [
        "img = get_image('https://icatcare.org/app/uploads/2018/07/Thinking-of-getting-a-cat.png')\n",
        "features = get_features(img)\n",
        "print(\"{}\\n shape: {}\".format(features,features.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cJMzCooNKpb"
      },
      "outputs": [],
      "source": [
        "# from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "\n",
        "mypath = join(os.getcwd(),'train')\n",
        "\n",
        "cats_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('cat')]\n",
        "dogs_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('dog')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMcypAC7NRJS",
        "outputId": "632a985d-7249-4094-c54c-90eb3428ffc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats: 12500 and dogs: 12500\n"
          ]
        }
      ],
      "source": [
        "print(\"cats: {} and dogs: {}\".format(len(cats_imgs),len(dogs_imgs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE7V7QzpNS6y"
      },
      "outputs": [],
      "source": [
        "Nmax = 5000\n",
        "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
        "dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLu5lLyhNX8r"
      },
      "outputs": [],
      "source": [
        "Y_cats = np.array(Nmax * [1])\n",
        "Y_dogs = np.array(Nmax * [0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ080R-dNbuT"
      },
      "outputs": [],
      "source": [
        "X_cvd = np.vstack([cats_features,dogs_features])\n",
        "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awihO1E5NexD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68yzU8tfNiMd",
        "outputId": "60a026a9-2378-496f-d4be-a177d26dec31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set score: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lg = LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "print(\"Test set score: {:.2f}\".format(lg.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSlOz--sOBEF",
        "outputId": "e6bf11c4-a9be-4d10-8894-c9eff3df43d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for N = 10:\n",
            "Accuracy: 1.00\n",
            "Computational Time (seconds): 7.46\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 10, 'n_estimators': 100}\n",
            "\n",
            "Results for N = 100:\n",
            "Accuracy: 0.90\n",
            "Computational Time (seconds): 5.38\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 20, 'n_estimators': 50}\n",
            "\n",
            "Results for N = 500:\n",
            "Accuracy: 0.94\n",
            "Computational Time (seconds): 24.32\n",
            "Best Hyperparameters:\n",
            "{'max_depth': None, 'n_estimators': 100}\n",
            "\n",
            "Results for N = 1000:\n",
            "Accuracy: 0.93\n",
            "Computational Time (seconds): 58.76\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 10, 'n_estimators': 100}\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def extract_features(img_paths, fe_mod):\n",
        "    features = []\n",
        "    for img_path in img_paths:\n",
        "        img = get_image(img_path)\n",
        "        img_features = get_features(img)\n",
        "        features.append(img_features.ravel())\n",
        "    return np.array(features)\n",
        "\n",
        "def train_classifier(X_train, y_train, param_grid):\n",
        "    clf = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "    start_time = time.time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    return grid_search, end_time - start_time\n",
        "\n",
        "# Different values of N\n",
        "N_values = [10, 100, 500, 1000]\n",
        "\n",
        "for N in N_values:\n",
        "    # Sample N images for cats and dogs\n",
        "    cats_features = extract_features(cats_imgs[:N], fe_mod)\n",
        "    dogs_features = extract_features(dogs_imgs[:N], fe_mod)\n",
        "\n",
        "    # Create labels\n",
        "    Y_cats = np.array(N * [1])\n",
        "    Y_dogs = np.array(N * [0])\n",
        "\n",
        "    # Stack features and labels\n",
        "    X_cvd = np.vstack([cats_features, dogs_features])\n",
        "    Y_cvd = np.hstack([Y_cats, Y_dogs])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Define the parameter grid for RandomForestClassifier (adjust as needed)\n",
        "    param_grid = {\n",
        "        'n_estimators': [10, 50, 100],\n",
        "        'max_depth': [None, 10, 20],\n",
        "    }\n",
        "\n",
        "    # Train the classifier and measure computational time\n",
        "    clf, training_time = train_classifier(X_train_scaled, y_train, param_grid)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Report results\n",
        "    print(f\"\\nResults for N = {N}:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Computational Time (seconds): {training_time:.2f}\")\n",
        "\n",
        "    # Print best hyperparameters from the grid search\n",
        "    print(\"Best Hyperparameters:\")\n",
        "    print(clf.best_params_)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}