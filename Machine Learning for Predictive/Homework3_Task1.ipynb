{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdQLOBrAKe6J"
      },
      "outputs": [],
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 1q2gnTZHNP5_DZFMc4VHO7Fah6X4vZcR0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu9mFkjPPQgr",
        "outputId": "03fd8749-508e-487b-be0f-df3ada00dfaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q2gnTZHNP5_DZFMc4VHO7Fah6X4vZcR0\n",
            "To: /content/SqueezeNet_v1.2-master.zip\n",
            "100% 4.59M/4.59M [00:00<00:00, 57.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 18_e1gBcQxf_S-FnhxIc3b-D8mVNFZ9WV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYV6vjatUDeC",
        "outputId": "c7443cef-b54e-43a2-d6f6-1c4752636a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18_e1gBcQxf_S-FnhxIc3b-D8mVNFZ9WV\n",
            "To: /content/kaggle.json\n",
            "100% 65.0/65.0 [00:00<00:00, 240kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_WGwVP8rWD",
        "outputId": "471f8f6e-6fa9-4ceb-dd13-f36be28d4ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIqrqS7v9EeQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Set your Kaggle API credentials\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"maryamsaa\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"b73d47e88e6150c7dbb3ae61c96b1024\"\n",
        "\n",
        "# Specify the competition name\n",
        "competition_name = \"dogs-vs-cats-redux-kernels-edition\"\n",
        "\n",
        "# Set the working directory to where you want to download the files\n",
        "#os.chdir(\"my-work\")\n",
        "\n",
        "# Create a Kaggle API object\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the train.zip file\n",
        "api.competition_download_file(competition=competition_name, file_name=\"train.zip\")\n",
        "\n",
        "# Download the test.zip file\n",
        "api.competition_download_file(competition=competition_name, file_name=\"test.zip\")\n"
      ],
      "metadata": {
        "id": "OO-gX5loxwau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75d1bda-6e82-4a64-c791-ab4f64f81df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 544M/544M [00:07<00:00, 74.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading test.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 271M/271M [00:04<00:00, 62.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbnvdcpW9bd4"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the paths to the zip files\n",
        "train_zip_path = \"train.zip\"\n",
        "test_zip_path = \"test.zip\"\n",
        "SqueezeNet_zip_path = \"SqueezeNet_v1.2-master.zip\"\n",
        "\n",
        "\n",
        "# Extract the contents of train.zip in the same directory\n",
        "with zipfile.ZipFile(train_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(train_zip_path))\n",
        "\n",
        "# Extract the contents of test.zip in the same directory\n",
        "with zipfile.ZipFile(test_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(test_zip_path))\n",
        "\n",
        "# Extract the contents of SqueezeNet_v1.2-master.zip in the same directory\n",
        "with zipfile.ZipFile(SqueezeNet_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.dirname(SqueezeNet_zip_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eImuZIIEqgYV",
        "outputId": "fd75b7a5-402f-4f57-94c4-e533947ec400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet==1.5.1\n",
            "  Downloading mxnet-1.5.1-py2.py3-none-manylinux1_x86_64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet==1.5.1) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet==1.5.1)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet==1.5.1) (2023.7.22)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install mxnet==1.5.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJ__0yuq8I8"
      },
      "outputs": [],
      "source": [
        "import mxnet as mx\n",
        "import numpy as np\n",
        "np.bool = np.bool_\n",
        "\n",
        "symbol_file = 'SqueezeNet_v1.2-master/model'\n",
        "params_file = 'SqueezeNet_v1.2-master/model-0000.params'\n",
        "\n",
        "# Load the model\n",
        "sym, arg_params, aux_params = mx.model.load_checkpoint(symbol_file, 0)\n",
        "mod = mx.mod.Module(symbol=sym, context=mx.cpu(), label_names=None)\n",
        "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))],\n",
        "         label_shapes=mod._label_shapes)\n",
        "mod.set_params(arg_params, aux_params, allow_missing=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJxXfKtbCqdy"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "# define a simple data batch\n",
        "from collections import namedtuple\n",
        "Batch = namedtuple('Batch', ['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0euR3JGpDOMR"
      },
      "outputs": [],
      "source": [
        "def get_image(url, show=False):\n",
        "    if url.startswith('http'):\n",
        "        # download and show the image\n",
        "        fname = mx.test_utils.download(url)\n",
        "    else:\n",
        "        fname = url\n",
        "    img = cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB)\n",
        "    if img is None:\n",
        "         return None\n",
        "    if show:\n",
        "         plt.imshow(img)\n",
        "         plt.axis('off')\n",
        "    # convert into format (batch, RGB, width, height)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = np.swapaxes(img, 0, 2)\n",
        "    img = np.swapaxes(img, 1, 2)\n",
        "    img = img[np.newaxis, :]\n",
        "    return img\n",
        "\n",
        "def predict(url):\n",
        "    img = get_image(url, show=True)\n",
        "    # compute the predict probabilities\n",
        "    mod.forward(Batch([mx.nd.array(img)]))\n",
        "    prob = mod.get_outputs()[0].asnumpy()\n",
        "    # print the top-5\n",
        "    prob = np.squeeze(prob)\n",
        "    a = np.argsort(prob)[::-1]\n",
        "    for i in a[0:5]:\n",
        "        print('probability=%f, class=%s' %(prob[i], labels[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMN-Pe5CDf_P",
        "outputId": "a2752b75-cba2-4337-bb06-81199d36442a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fire9_concat_output',\n",
              " 'dropout0_output',\n",
              " 'conv10_conv_weight',\n",
              " 'conv10_conv_bias',\n",
              " 'conv10_conv_output',\n",
              " 'conv10_relu_output',\n",
              " 'pool10_output',\n",
              " 'flatten0_output',\n",
              " 'softmax_label',\n",
              " 'softmax_output']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# list the last 10 layers\n",
        "all_layers = sym.get_internals()\n",
        "all_layers.list_outputs()[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYI6ZauFDlo_"
      },
      "outputs": [],
      "source": [
        "fe_sym = all_layers['flatten0_output']\n",
        "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
        "fe_mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])\n",
        "fe_mod.set_params(arg_params, aux_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UmvC2h6DpTr"
      },
      "outputs": [],
      "source": [
        "def get_features(img):\n",
        "    fe_mod.forward(Batch([mx.nd.array(img)]))\n",
        "    features = fe_mod.get_outputs()[0].asnumpy()\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atTGGvwkDsWI"
      },
      "outputs": [],
      "source": [
        "img = get_image('https://icatcare.org/app/uploads/2018/07/Thinking-of-getting-a-cat.png')\n",
        "features = get_features(img)\n",
        "#print(\"{}\\n shape: {}\".format(features,features.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGcr5QnFDyJB"
      },
      "outputs": [],
      "source": [
        "# from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "\n",
        "mypath = join(os.getcwd(),'train')\n",
        "\n",
        "cats_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('cat')]\n",
        "dogs_imgs = [join(mypath,f) for f in listdir(mypath) if f.startswith('dog')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld70yTrBD9xX",
        "outputId": "7caf2cb6-a3a0-44e3-fe09-909859d0f821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cats: 12500 and dogs: 12500\n"
          ]
        }
      ],
      "source": [
        "print(\"cats: {} and dogs: {}\".format(len(cats_imgs),len(dogs_imgs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I46BQEuKEBqQ"
      },
      "outputs": [],
      "source": [
        "Nmax = 50\n",
        "cats_features = [get_features(get_image(img)).ravel() for img in cats_imgs[:Nmax]]\n",
        "dogs_features = [get_features(get_image(img)).ravel() for img in dogs_imgs[:Nmax]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9elPLA9DEGqo"
      },
      "outputs": [],
      "source": [
        "Y_cats = np.array(Nmax * [1])\n",
        "Y_dogs = np.array(Nmax * [0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enoWlasMEK64"
      },
      "outputs": [],
      "source": [
        "X_cvd = np.vstack([cats_features,dogs_features])\n",
        "Y_cvd = np.vstack([Y_cats,Y_dogs]).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBeAkywsEPnA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLnMqE4iETL4",
        "outputId": "e152c1b8-799c-4150-fa1b-7f793be334d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set score: 0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lg = LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "print(\"Test set score: {:.2f}\".format(lg.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVnXGCwVIshx",
        "outputId": "1338e201-dc2b-4a67-cb20-e8fb730638c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for N = 10:\n",
            "Accuracy: 1.00\n",
            "Computational Time (seconds): 4.41\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 10, 'n_estimators': 10}\n",
            "\n",
            "Results for N = 100:\n",
            "Accuracy: 0.85\n",
            "Computational Time (seconds): 5.27\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 20, 'n_estimators': 50}\n",
            "\n",
            "Results for N = 500:\n",
            "Accuracy: 0.95\n",
            "Computational Time (seconds): 26.51\n",
            "Best Hyperparameters:\n",
            "{'max_depth': 20, 'n_estimators': 100}\n",
            "\n",
            "Results for N = 1000:\n",
            "Accuracy: 0.95\n",
            "Computational Time (seconds): 61.14\n",
            "Best Hyperparameters:\n",
            "{'max_depth': None, 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def extract_features(img_paths, fe_mod):\n",
        "    features = []\n",
        "    for img_path in img_paths:\n",
        "        img = get_image(img_path)\n",
        "        img_features = get_features(img)\n",
        "        features.append(img_features.ravel())\n",
        "    return np.array(features)\n",
        "\n",
        "def train_classifier(X_train, y_train, param_grid):\n",
        "    clf = RandomForestClassifier()\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "    start_time = time.time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    return grid_search, end_time - start_time\n",
        "\n",
        "# Different values of N\n",
        "N_values = [10, 100, 500, 1000]\n",
        "\n",
        "for N in N_values:\n",
        "    # Sample N images for cats and dogs\n",
        "    cats_features = extract_features(cats_imgs[:N], fe_mod)\n",
        "    dogs_features = extract_features(dogs_imgs[:N], fe_mod)\n",
        "\n",
        "    # Create labels\n",
        "    Y_cats = np.array(N * [1])\n",
        "    Y_dogs = np.array(N * [0])\n",
        "\n",
        "    # Stack features and labels\n",
        "    X_cvd = np.vstack([cats_features, dogs_features])\n",
        "    Y_cvd = np.hstack([Y_cats, Y_dogs])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_cvd, Y_cvd, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Define the parameter grid for RandomForestClassifier (adjust as needed)\n",
        "    param_grid = {\n",
        "        'n_estimators': [10, 50, 100],\n",
        "        'max_depth': [None, 10, 20],\n",
        "    }\n",
        "\n",
        "    # Train the classifier and measure computational time\n",
        "    clf, training_time = train_classifier(X_train_scaled, y_train, param_grid)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Report results\n",
        "    print(f\"\\nResults for N = {N}:\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Computational Time (seconds): {training_time:.2f}\")\n",
        "\n",
        "    # Print best hyperparameters from the grid search\n",
        "    print(\"Best Hyperparameters:\")\n",
        "    print(clf.best_params_)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}